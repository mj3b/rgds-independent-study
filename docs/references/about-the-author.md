## About the Author

**Mark Julius Banasihan** designs decision governance systems for high-stakes, regulated environments where speed, accountability, and defensibility must coexist.

His work focuses on a persistent failure mode in complex organizations: decisions that are technically sound yet operationally fragile because their rationale, evidence, and risk posture cannot be reconstructed when scrutiny arrives. This breakdown becomes acute when artificial intelligence accelerates analysis and execution without equivalent discipline in decision ownership and documentation.

Mark approaches AI governance from a decision-first perspective. Rather than treating AI as an autonomous actor or a productivity layer, he designs bounded analytical systems that strengthen human judgment, preserve explicit accountability, and produce audit-ready decision artifacts at the moment choices are made. His frameworks emphasize clarity over automation, restraint over novelty, and structure as a means of protecting expert judgment rather than replacing it.

RGDS (Regulated Gate Decision Support) emerged from this perspective. It is presented as a reference model for organizations operating in environments shaped by regulatory review, inspection risk, and downstream consequence. The work integrates principles from decision science, systems thinking, and organizational design to address a simple question with difficult implications: how to accelerate decisions without weakening trust in how those decisions were reached.

Mark’s contribution is not centered on tools, models, or platforms. It lies in making decision logic explicit, evidence-linked, and reviewable so that organizations can move faster precisely because they are more disciplined. His work is intended for practitioners, regulators, and leaders who recognize that governance maturity is no longer separate from execution, and that credibility is built through structure, not rhetoric.

RGDS is shared as an independent research effort and is meant to be tested, challenged, and adapted in real operational settings. Its value is measured by whether it helps organizations make fewer irreversible mistakes, defend their choices under scrutiny, and maintain human authority in an AI-accelerated world.


**Research & Practice Framework:**

Mark approaches AI governance using principles from decision science, systems theory, and organizational psychology—not AI optimization alone. His mental models are informed by:


- Disciplined experimental design (clear hypotheses, testable claims, failure modes)
- Regulatory frameworks (FDA guidance, audit defensibility, traceability)
- Organizational dynamics (stakeholder skepticism, change resistance, trust-building)

### Core Expertise

**Decision Architecture & Non-Agentic AI Governance:**


- Designing decision-first (not automation-first) frameworks for regulated, phase-gated workflows
- Formalizing decision discipline through schema enforcement, evidence classification, and immutable audit trails
- Building governance boundaries that keep AI in analytical support roles (summarization, extraction, comparison, synthesis)
- Preserving singular human accountability even in AI-assisted workflows

**Applied AI Research Translation:**


- Extracting explicit, falsifiable claims from published research
- Defining bounded tasks with constraints, failure modes, and oversight points
- Enforcing abstention when evidence is insufficient
- Mapping research signals to decision-ready evidence with full traceability

**AI-Assisted Workflow Design & Change Management:**


- Identifying where teams lose time, context, or clarity (evidence synthesis, version control, protocol alignment, regulatory submission assembly)
- Designing tools that respect how humans actually work—not forcing adoption, but removing friction through iteration
- Building trust in AI-assisted systems by making governance explicit, transparent, and audit-ready
- Managing stakeholder skepticism by treating caution as reasonable and designing small, contained pilots with clear success metrics

**Executive Communication & Decision Analytics:**


- Translating technical complexity into narratives leaders can act on
- Structuring insights around three core points: what we learned, what decision is needed, what risk we face if we defer
- Building decision-ready dashboards that reveal patterns without overwhelming detail
- Reducing time-to-decision through clarity and trust in underlying data and logic

---

### The RGDS Research Program

RGDS emerged from a central research question:

**How can high-stakes, regulated organizations use artificial intelligence to support phase-gate decisions without undermining human authority, regulatory accountability, or audit defensibility?**

More specifically: **Can AI meaningfully accelerate decisions without becoming the decision-maker?**

**Development:**

- **v1.0–v1.2:** Baseline decision discipline, IND workflow refinement, governance boundaries
- **v1.3–v1.4:** Governance maturity, evidence completeness states, author-at-risk modeling, cross-program intelligence
- **v2.0** (in progress): Expanded logs, analytics, and governance artifacts

**Reference Implementations:**


- Schema-validated decision logs enforcing structured evidence and risk articulation
- Canonical examples demonstrating accept, conditional-go, no-go, and defer outcomes
- Governance covenants defining AI boundaries and human approval checkpoints
- Translation-negative examples proving the framework enforces rigor (rejecting weak claims) rather than rationalizing predetermined outcomes
- Audit-ready artifacts with full traceability from evidence to decision to rationale

**Core Principles:**


1. AI never makes decisions—only provides bounded analytical support
2. Human authority is explicit and recorded (named owner, defined scope)
3. Evidence precedes outcomes (no decision without documented evidence states)
4. Uncertainty is acknowledged, not hidden (confidence levels, gaps, risks recorded explicitly)
5. The system remains valid without AI (decision architecture doesn't collapse if AI is removed)

---

### Working Philosophy

Mark's approach rests on several non-negotiable principles:


1. **People define correctness.** Domain experts (scientists, regulatory specialists, engineers) define what counts as correct. Mark's role is helping that correctness move through systems, tools, and processes without dilution or distortion.


2. **Structure protects judgment.** Decision frameworks succeed when they reduce avoidable errors, repetitive work, and context-switching—freeing human experts to focus on questions that truly require their expertise and judgment.


3. **Technology should adapt to humans, not the reverse.** When AI tools don't fit how people actually work, adoption fails. Success requires observing friction, iterating in feedback loops, and making tools invisible support rather than friction sources.


4. **Skepticism in high-stakes environments is rational.** In regulated, high-consequence settings, caution about new methods is a feature, not a bug. Earning trust means demonstrating discipline, transparency, and genuine respect for stakeholders' obligations and comfort levels.


5. **Governance made explicit beats governance made implicit.** The most defensible systems are those where decision ownership, assumptions, dependencies, and uncertainty are made visible, reviewable, and traceable—not hidden in meetings or email threads.

---

### Thought Leadership & Communication

Mark actively contributes to conversations on decision-centric AI, responsible governance, and the human future of work:

- **Decision Discipline:** Frameworks for making decisions explicit, reviewable, and owned before downstream commitments crystallize


- **Applied Research Translation:** Extracting falsifiable claims from published research and translating them into decision-ready evidence


- **AI Change Management:** Building trust in skeptical organizations through small pilots, transparent boundaries, and human-in-the-loop validation


- **Executive Communication:** Teaching leaders to cut noise and focus on what matters—what we learned, what decision is needed, what risk we face if we defer


- **Systems Thinking:** Exploring how organizations form and evolve categories of knowledge, and how networks and diversity shape innovation

---

### Current Work & Availability

Mark is actively available for:

- **Consulting engagements** on decision governance, AI integration strategy, and change management in regulated delivery


- **Implementation partnerships** to pilot RGDS in biopharmaceutical and biotech organizations or equivalent delivery partners


- **Collaborative research** exploring how organizations make governance explicit, defensible, and scalable while maintaining regulatory accountability

He views RGDS not as a finished product or proprietary asset, but as a foundation—a reference model for decision-centric AI adoption that other organizations can validate, adapt, and extend within their own regulatory and operational contexts.

## Connect

- **GitHub:** [https://github.com/mj3b](https://github.com/mj3b)
- **LinkedIn:** [https://linkedin.com/in/markjuliusbanasihan/](https://linkedin.com/in/markjuliusbanasihan/)
- **Email:** [markjuliusbanasihan@gmail.com](mailto:markjuliusbanasihan@gmail.com)
- **Location:** Atlanta, Georgia, United States

---


