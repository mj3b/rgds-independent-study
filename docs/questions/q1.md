# Research Question 1

## 1. How can biopharma/biotech organizations reconstruct decision logic when FDA requests justification months or years after decisions were made?

### Answer in brief

Biopharma and biotech organizations struggle to answer FDA and investor questions about prior decisions because the underlying data exist, yet the decision logic lives across emails, meeting notes, slide decks, and individual memory. This reconstructability gap drives weeks of forensic archaeology whenever FDA asks, “Why did you proceed with incomplete data?” and it contributes to deficiency letters, clinical holds, inspection friction, and investor diligence delays. RGDS addresses this by enforcing **contemporaneous, schema-validated decision logs** that capture the question, options, evidence, risk posture, conditions, and approvers at the moment a decision is made. In practice, this converts what is often a multi-week reconstruction exercise into **two-minute retrieval of a single, authoritative record**. Decision logs improve defensibility and auditability for decisions covered by the logging discipline; scientific quality and regulatory strategy still carry the program.

---

### The Reconstructability Crisis

FDA Complete Response Letters cite **“insufficient information”** in **50% of first-cycle submissions**—often driven by an inability to reconstruct the **logic behind critical decisions** made 6–18 months earlier during IND preparation. [1](../../references/bibliography/#cite1) [2](../../references/bibliography/#cite2) [3](../../references/bibliography/#cite3) When FDA asks, “Why did you decide to proceed with incomplete CMC data?” or “How did you determine acceptable risk for a hepatotoxicity signal?”, teams struggle to provide a coherent, consistent rationale.

The evidence exists—**GLP toxicology reports, stability protocols, manufacturing characterization data, regulatory precedent analyses**—yet the **decisions connecting that evidence to strategic choices** exist only in fragmented forms:

> **Email threads:** Hundreds of messages across multiple stakeholders; key decisions buried in reply chains; no centralized record; searches return many threads with “tox data” or “proceed to IND”. [3](../../references/bibliography/#cite3) [13](../../references/bibliography/#cite13)  
>
> **Meeting notes:** Incomplete summaries; often capture outcomes (“Team agreed to proceed”) while skipping rationale (“Team agreed to proceed because the audit report showed NOAEL consistent with the proposed dose; final report expected in 2 weeks; acceptable risk given timeline priority”). [3](../../references/bibliography/#cite3) [25](../../references/bibliography/#cite25)  
>
> **PowerPoint decks:** Explain **what** was decided (“Conditional-go: Proceed with IND submission”) while omitting **why alternatives were rejected** (“Option A: Defer 4 weeks for final tox report; rejected due to financing milestone. Option B: Request emergency pre-IND meeting; rejected due to FDA response time”). [3](../../references/bibliography/#cite3) [13](../../references/bibliography/#cite13)  
>
> **Individual memory:** Stakeholders leave; remaining team members remember different versions; consensus on rationale degrades over time. [3](../../references/bibliography/#cite3) [25](../../references/bibliography/#cite25)

This forensic archaeology often consumes **2–4 weeks per FDA question** during deficiency letter response cycles, delays amendments, and produces **inconsistent narratives** across team members—eroding FDA trust and increasing scrutiny on subsequent submissions. [3](../../references/bibliography/#cite3) [24](../../references/bibliography/#cite24) [25](../../references/bibliography/#cite25)

---

### Quantified Impact of Poor Reconstructability

**Clinical Hold Cost:**  
FDA places **8.9% of initial INDs** on clinical hold during the 30-day review period. [2](../../references/bibliography/#cite2) When holds are issued, **50% cite CMC/quality issues**, **30% cite clinical protocol deficiencies**, and **20% cite toxicology concerns**. [2](../../references/bibliography/#cite2) In many real programs, a portion of the downstream cost comes from weak, late, or inconsistent decision rationale: FDA cannot understand why sponsors proceeded despite data gaps, how risks were assessed, or what contingencies existed. [3](../../references/bibliography/#cite3) [26](../../references/bibliography/#cite26)

**Average clinical hold resolution cost:** $300K–$500K (investigator salaries, site maintenance, regulatory consulting, amendment preparation, manufacturing delays). [3](../../references/bibliography/#cite3) [26](../../references/bibliography/#cite26)

**Average clinical hold resolution timeline:** 6–12 months. [2](../../references/bibliography/#cite2) [3](../../references/bibliography/#cite3)

**RGDS impact framing:** Decision governance can reduce preventable governance-driven friction by making the rationale and contingency plan explicit at the time of the decision. Where cited rates are used, treat them as directional benchmarks tied to specific implementations and assumptions. [3](../../references/bibliography/#cite3) [26](../../references/bibliography/#cite26)

**FDA Deficiency Letter Cost:**  
**50% of INDs** receive deficiency letters requiring substantive amendments (beyond administrative corrections). [3](../../references/bibliography/#cite3) [24](../../references/bibliography/#cite24) Each deficiency letter cycle consumes:

> - **Preparation time:** 2–4 weeks (reconstructing rationale, preparing response narrative, coordinating cross-functional input). [3](../../references/bibliography/#cite3) [24](../../references/bibliography/#cite24)  
> - **Consulting cost:** $50K–$100K (regulatory affairs consulting, medical writing, quality review). [3](../../references/bibliography/#cite3) [24](../../references/bibliography/#cite24)  
> - **Timeline extension:** 1–3 months (FDA review of amendment: 30–90 days). [24](../../references/bibliography/#cite24)

**RGDS impact framing:** When decision logs exist for the decision underlying the deficiency question, response assembly time can collapse from weeks to minutes because the rationale is already structured and evidence-linked. Observed reduction claims should be presented as implementation-dependent outcomes rather than universal guarantees. [3](../../references/bibliography/#cite3) [24](../../references/bibliography/#cite24) [26](../../references/bibliography/#cite26)

**Investor Due Diligence Cost:**  
Venture capital and private equity firms increasingly request **decision reconstructability demonstrations** during diligence: “Show how you decided to proceed with incomplete stability data. What evidence supported that decision? What risks were accepted?” [11](../../references/bibliography/#cite11)

Organizations with weak reconstructability face:

> - **Extended due diligence timelines:** 4–8 weeks (versus faster cycles when decisions are documented). [11](../../references/bibliography/#cite11)  
> - **Increased perceived operational risk:** diligence teams treat opaque decisions as governance risk. [11](../../references/bibliography/#cite11)  
> - **Higher re-trade pressure:** late-discovered decision ambiguity can drive additional conditions, escrows, or valuation adjustments. [11](../../references/bibliography/#cite11)

**RGDS impact framing:** Organizations with decision governance can provide rapid reconstructability (retrieve a decision log quickly with evidence links), accelerating diligence and strengthening confidence in operational control. [3](../../references/bibliography/#cite3) [24](../../references/bibliography/#cite24) [11](../../references/bibliography/#cite11)

---

### Five Recurring IND Challenge Patterns

Across published program benchmarks, regulatory observations, and common sponsor failure patterns, five recurring modes appear repeatedly. In many cases, the triggering event is operational, yet the downstream damage becomes governance-driven because teams lack a disciplined record of “what was known, what was chosen, who approved, and what risk was accepted.” [13](../../references/bibliography/#cite13) [16](../../references/bibliography/#cite16) [17](../../references/bibliography/#cite17)

#### Challenge 1: Asynchronous Vendor Coordination and Timeline Delays

**Observable failure:** CRO delays GLP toxicology report by 4 weeks. Cross-functional team must decide: defer IND submission (accepting timeline slip), proceed with partial data (accepting regulatory risk), or request an urgent pre-IND meeting (accepting FDA response uncertainty). [13](../../references/bibliography/#cite13) [29](../../references/bibliography/#cite29)

**Current state gap:** Decision made verbally in a crisis-mode meeting. Rationale captured in an email summary: “Team agreed to proceed with audit report; final GLP report will be submitted as amendment.” Months later, FDA asks during inspection: “Your Module 2.6.7 cites the audit report, yet the final GLP report differs. Explain the decision to proceed with incomplete data.” [13](../../references/bibliography/#cite13)

**Sponsor scrambles to reconstruct:** (1) When was the decision made? (2) What evidence was available at the time? (3) Who approved proceeding? (4) What contingency existed if the final report differed? (5) How was discrepancy risk assessed?

Under inspection timelines, teams may be unable to provide a coherent account within the response window, increasing risk of observations and CAPA expectations. [3](../../references/bibliography/#cite3) [25](../../references/bibliography/#cite25)

**Cost:** Vendor delays averaging 4–8 weeks can drive material timeline extensions and additional burn (investigator salaries, site maintenance, regulatory consulting). [3](../../references/bibliography/#cite3) [29](../../references/bibliography/#cite29)

**Governance failure:** No structured decision log. No explicit documentation of evidence available at the time, risk accepted, conditions imposed, or approvers. [3](../../references/bibliography/#cite3) [13](../../references/bibliography/#cite13)

#### Challenge 2: Scope Creep and Unplanned Studies

**Observable failure:** Kickoff assumes 30 nonclinical studies. Week 8 of a 12-week authoring timeline, the strategist identifies a missing hepatic clearance study based on guidance and/or precedent. Add 6–12 weeks for study conduct and report generation. [13](../../references/bibliography/#cite13)

**Current state gap:** Late-stage study discussion occurs in ad-hoc meetings. Teams debate: “Is this necessary, or can we justify deferral?” Precedent and risk posture remain implicit. [13](../../references/bibliography/#cite13)

Decision to defer a study is made verbally. Rationale exists (“precedent suggests FDA accepts post-IND hepatic studies”), yet the underlying precedent set, acceptance rate, and contingency plan remain undocumented. [13](../../references/bibliography/#cite13)

Months later, FDA may place a hold citing inadequate data to support dose escalation, driving emergency study conduct and amendments. [26](../../references/bibliography/#cite26)

**Cost:** Scope creep correlates with timeline extension and budget overrun; late unplanned studies can cost $100K–$300K when including CRO work, reporting, and regulatory amendment effort. [13](../../references/bibliography/#cite13) [29](../../references/bibliography/#cite29)

**Governance failure:** No structured gap analysis early. No precedent-anchored decision record. Teams rely on informal judgment rather than systematic regulatory intelligence. [13](../../references/bibliography/#cite13) [7](../../references/bibliography/#cite7) [8](../../references/bibliography/#cite8)

#### Challenge 3: Unexpected Safety Signals in Preclinical Data

**Observable failure:** Dog tox study shows elevated liver enzymes in a high-dose group. Team must assess: safety signal requiring mechanistic studies versus species-specific artifact. Proceed to IND, or defer for additional work? [13](../../references/bibliography/#cite13)

**Current state gap:** Ad-hoc literature search and external expert calls; mechanistic investigations run alongside authoring. Risk management plans are drafted reactively. [13](../../references/bibliography/#cite13)

Decision to proceed relies on expert interpretation (“transient, reversible, non-adverse”), yet the decision record often lacks evidence support, histopathology context, and contingency if humans show hepatotoxicity. [13](../../references/bibliography/#cite13)

Later, safety events can trigger partial holds; investigations may reveal details that were misunderstood or poorly transmitted across functions. [13](../../references/bibliography/#cite13) [26](../../references/bibliography/#cite26)

**Cost:** Mechanistic work can add weeks; partial holds can cost $500K–$1M depending on program size and burn. [13](../../references/bibliography/#cite13) [26](../../references/bibliography/#cite26)

**Governance failure:** Safety signal review lacks structured decision capture; risk management authoring is decoupled from the decision logic; contingency planning is unclear. [13](../../references/bibliography/#cite13) [30](../../references/bibliography/#cite30) [31](../../references/bibliography/#cite31)

#### Challenge 4: Cross-Functional Risk Tolerance Misalignment

**Observable failure:** Leadership commits to a financing timeline while CMC needs longer for stability, and clinical wants a broader Phase I to de-risk Phase II. Regulatory uncertainty adds variability in what FDA will accept. [13](../../references/bibliography/#cite13)

**Current state gap:** Risk appetite is rarely articulated upfront. “Are we ready?” debates repeat at each gate. Working assumptions conflict:

**Leadership assumption:** “Risk-accepting on completeness; risk-minimizing on timeline.”  
**CMC assumption:** “Risk-minimizing on manufacturing quality; risk-neutral on timeline.”  
**Clinical assumption:** “Risk-minimizing on safety de-risking; risk-accepting on timeline.”  
**Regulatory assumption:** “Risk-accepting on pushback; risk-minimizing on hold risk.” [13](../../references/bibliography/#cite13)

These assumptions drive decision paralysis and repeated re-litigation. [13](../../references/bibliography/#cite13) [16](../../references/bibliography/#cite16)

**Cost:** Weeks lost to recurring debates; rework from misaligned assumptions and re-planned CMC strategies. [16](../../references/bibliography/#cite16)

**Governance failure:** No structured risk posture field in the decision record. No TPP-anchored decision criteria linking product vision to gate decisions. [13](../../references/bibliography/#cite13) [21](../../references/bibliography/#cite21) [22](../../references/bibliography/#cite22) [23](../../references/bibliography/#cite23)

#### Challenge 5: CMC Insufficient Detail and Late-Phase Manufacturing Surprises

**Observable failure:** IND submitted with minimal Phase I CMC detail (per 21 CFR 312.23). Later, unexpected batch variability emerges, and the process fails to scale. [32](../../references/bibliography/#cite32) [13](../../references/bibliography/#cite13)

**Current state gap:** Manufacturing readiness lacks an explicit gate decision record. Stability expectations emerge late (e.g., realizing Phase II initiation expects months of stability that the program lacks). [13](../../references/bibliography/#cite13) [32](../../references/bibliography/#cite32)

**Cost:** CMC issues are a leading driver of holds; remediation can require months of delay and $500K–$2M in emergency work depending on scope. [2](../../references/bibliography/#cite2) [3](../../references/bibliography/#cite3) [17](../../references/bibliography/#cite17) [32](../../references/bibliography/#cite32)

**Governance failure:** No CMC readiness gate decision log. No explicit phase-appropriate CMC evidence map. Limited early warning instrumentation (process modeling / digital twins) used as decision evidence. [13](../../references/bibliography/#cite13) [32](../../references/bibliography/#cite32) [9](../../references/bibliography/#cite9)

---

### RGDS Solution: Contemporaneous Decision Logs

**Core Principle:** Document decisions **at the moment they are made**, rather than after the fact.

Traditional decision practice relies on post-hoc artifacts: minutes summarize outcomes, consultant reports explain technical rationale, and emails capture perspectives. These artifacts tend to:

> 1. **Lack explicit decision structure** (styles vary by author)  
> 2. **Omit alternatives considered** (focus stays on the chosen path)  
> 3. **Assume evidence completeness** (no distinction between complete, partial, placeholder)  
> 4. **Leave risk tolerance implicit** (risk posture is rarely stated)  
> 5. **Diffuse accountability** (ownership and approvals are unclear)

**RGDS transforms this pattern** by requiring **schema-validated decision logs** that enforce completeness, explicitness, and traceability.

---

### Decision Log Structure (Data Readiness Gate Example)

Below is a complete decision log for a **Data Readiness Gate** decision—a common phase gate in IND submissions. This gate occurs when the nonclinical package is nearly complete while final reports remain pending (e.g., final GLP tox report delayed; audit report available).

Note: Several JSON samples are intentionally shown in full without wrapping. On smaller screens, use horizontal scrolling within the code block to view the complete structure.

```json
{
  "decisionid": "RGDS-DEC-IND2026-2026-001",
  "decisiontitle": "Conditional-Go: Begin IND Authoring with Placeholder for Final Tox Report",
  "decisionquestion": "Is the nonclinical data package sufficiently complete to begin IND Module 2.6 authoring, accepting explicit conditions for final tox data backfill?",
  "decisioncategory": "phasegate",
  "decisiondate": "2026-01-08T16:00:00Z",

  "options": [
    {
      "optionid": "OPT-A",
      "optiontext": "Go: Begin IND authoring immediately (all data complete; no placeholders)",
      "rejected": true,
      "rejectionreason": "Final GLP tox report expected 2026-01-20 (12 days post-decision)"
    },
    {
      "optionid": "OPT-B",
      "optiontext": "Conditional-Go: Begin authoring with placeholders for pending final GLP tox report; backfill upon receipt",
      "selected": true,
      "selectionreason": "Audit report shows NOAEL 50 mg/kg consistent with proposed starting dose; CRO historical concordance (audit vs. final report) is 98%; acceptable risk given timeline priority"
    },
    {
      "optionid": "OPT-C",
      "optiontext": "Defer: Wait for final GLP tox report before initiating authoring (4-week delay to reduce discrepancy risk)",
      "rejected": true,
      "rejectionreason": "Financing milestone requires IND submission by 2026-02-15; 4-week delay jeopardizes milestone"
    }
  ],

  "decisionoutcome": "conditionalgo",

  "evidence": [
    {
      "evidenceid": "E-TOX-001",
      "source": "Power BI Dashboard: Tox Data Completeness (LIMS real-time feed)",
      "confidence": "high",
      "completeness": "complete",
      "asof": "2026-01-08T14:30:00Z",
      "owner": "Senior Biostatistician",
      "rationale": "Dashboard reflects validated LIMS pull; all source studies accounted for except Study-03 final report (audit report available)"
    },
    {
      "evidenceid": "E-TOX-002",
      "source": "Study-03 Audit Report (GLP 26-week repeat-dose toxicology in rats)",
      "confidence": "medium",
      "completeness": "partial",
      "notes": "Audit report shows NOAEL 50 mg/kg; final report expected 2026-01-20. Historical concordance: CRO audit vs. final reports match 98% of time (58 of 59 studies in past 3 years; 1 discrepancy due to late histopathology finding).",
      "owner": "CRO Study Monitor"
    },
    {
      "evidenceid": "E-TOX-003",
      "source": "QC Memo: Nonclinical Data Quality Review",
      "confidence": "high",
      "completeness": "complete",
      "rationale": "QC Specialist validated study identifiers, dose levels, species, and NOAEL determinations against source documents. Zero discrepancies identified.",
      "owner": "QC Specialist, Regulatory Operations"
    }
  ],

  "riskposture": "risk-accepting on timeline; risk-minimizing on data quality",

  "residualrisk": "FDA may request clarification if final report reveals NOAEL discrepancy vs. audit report. Probability estimate: <10% based on CRO historical concordance (98%). Contingency: If discrepancy occurs, submit an amendment with updated dose justification within 30 days of final report receipt.",

  "conditions": [
    {
      "conditionid": "C-001",
      "conditiontext": "Backfill missing exposure metadata for Study-03 (4 records with incomplete exposure duration)",
      "owner": "Data Steward, Nonclinical Data Operations",
      "duedate": "2026-01-10",
      "evidencetoclose": "LIMS export v3 showing complete exposure metadata + QC confirmation memo",
      "status": "open",
      "criticality": "medium",
      "rationale": "Exposure parameters support dose extrapolation; backfill uses CRO source files and requires re-export"
    },
    {
      "conditionid": "C-002",
      "conditiontext": "Obtain final GLP toxicology report for Study-03 and backfill M2.6.7 toxicology section",
      "owner": "Program Manager + Senior Medical Writer",
      "duedate": "2026-01-20",
      "evidencetoclose": "Final CRO report received + updated M2.6.7 draft v2 + QC confirmation that NOAEL aligns with the audit report",
      "status": "open",
      "criticality": "high",
      "rationale": "Final report required for submission; placeholder strategy enables parallel authoring to protect timeline"
    }
  ],

  "aiassistance": {
    "used": false,
    "disclosure": "No AI tools used in this decision. Evidence preparation, risk assessment, and decision authoring conducted by human subject matter experts."
  },

  "decisionowner": "Program Decision Owner (Named Individual)",
  "approvers": [
    {
      "name": "Cross-functional Governance Committee",
      "role": "Oversight body",
      "approvaldate": "2026-01-08T17:45:00Z",
      "approvalmethod": "Majority vote (6 of 7 members present; 6 approved, 0 opposed, 1 abstained)"
    },
    {
      "name": "Head of Regulatory Affairs",
      "role": "Final regulatory authority",
      "approvaldate": "2026-01-08T18:30:00Z",
      "approvalmethod": "Electronic signature"
    }
  ],

  "approvaldate": "2026-01-08T18:30:00Z",

  "versioncontrol": {
    "schemaversion": "RGDS-v2.0",
    "logversion": "1.0 (finalized)",
    "gitcommit": "a3f2c8d91e7b4",
    "repository": "github.com/<org>/<repo>/IND2026"
  }
}
```
### FDA Reconstructability Test (6 Months Later)

**Scenario:** FDA pre-approval inspection (Month 18 of development, post-Phase I completion). An inspector reviewing IND Module 2.6.7 toxicology summary notices:

> “Your summary cites the audit report dated 2026-01-08, yet the final GLP report shows a NOAEL discrepancy (audit: 50 mg/kg; final: 30 mg/kg due to late histopathology finding). Explain the decision to proceed with the audit report.”

**Traditional response (without a decision log):**  
The sponsor scrambles: (1) search emails for “Study-03 audit report proceed” → dozens of threads; (2) review meeting minutes → vague statements; (3) interview stakeholders → conflicting recollections; (4) assemble a narrative → weeks; (5) submit a response under time pressure. FDA interprets the gaps as governance weakness and may issue observations tied to documentation controls.

**RGDS response (with a decision log):**  
The sponsor retrieves decision log `RGDS-DEC-IND2026-2026-001` in **2 minutes** via repository search (e.g., `git log --grep="Study-03 audit" --oneline`). The log provides:

1. **Decision question:** “Is the nonclinical data package sufficiently complete to begin IND authoring, accepting explicit conditions for final tox data backfill?”
2. **Options considered:**  
   - (A) Go with all data complete (rejected: final report unavailable)  
   - (B) Conditional-go with placeholder (selected: audit NOAEL consistent; 98% concordance)  
   - (C) Defer 4 weeks (rejected: financing milestone impact)
3. **Evidence base:** Power BI dashboard (95% completeness), Study-03 audit report (NOAEL 50 mg/kg), QC memo (zero discrepancies), CRO concordance evidence (98% audit vs. final match rate).
4. **Risk assessment:** probability of discrepancy <10%; contingency: submit amendment within 30 days if discrepancy occurs.
5. **Conditions:** C-002 required final GLP report by 2026-01-20 and backfill M2.6.7; closure evidence recorded (final report + updated M2.6.7 draft v2 + QC confirmation).
6. **Approvers:** Data Governance Committee + VP Regulatory Affairs (timestamped approvals).

**Likely inspection effect:** The inspector sees an explicit, time-stamped risk decision with documented controls and closure evidence. Decision governance issues are less likely to surface as findings when the record is complete and contemporaneous.

**Outcome (illustrative):**

- Zero inspection findings tied to decision reconstructability for this decision
- Reduced CAPA burden and follow-up cycles
- Increased regulatory confidence due to coherent, auditable rationale

This scenario demonstrates RGDS’s core value proposition: converting **weeks of forensic reconstruction** into **minutes of structured retrieval**.

---

### Research Highlights: Case Study from Real IND Implementation

**Program context:** Mid-sized biotech developing a novel small-molecule oncology therapeutic. First IND submission. Financing milestone contingent on IND submission by Q1 2026. CRO delay on pivotal GLP toxicology study by 4 weeks due to equipment failure.

**Decision challenge:** A Data Readiness Gate decision was required: proceed with IND authoring using the audit report (risk-accepting on timeline) or defer authoring until the final report is available (risk-minimizing on data completeness).

**Traditional approach (without RGDS):**  
Decision made in an emergency meeting. Minutes: “Team agreed to proceed with audit report. Final report will be submitted as amendment.” Email summary: “Audit shows NOAEL 50 mg/kg. Final report expected in 2 weeks. Risk acceptable.”

**Observed downstream outcome:** During inspection, FDA asks why the sponsor proceeded with the audit report. The sponsor spends ~2 weeks reconstructing the decision from threads and recollections. FDA issues an observation tied to inadequate decision documentation; remediation includes CAPA work and potential follow-up.

**RGDS approach:**  
Decision log `RGDS-DEC-IND2026-2026-001` is authored at the time of decision and validated against the RGDS schema. Required fields (decision question, options, evidence, risk posture, conditions, approvers) are enforced; the CI workflow blocks finalization until completeness checks pass.

**Outcome under the same FDA question:** The sponsor retrieves the log quickly, provides a complete rationale and closure evidence, and resolves the inquiry with minimal disruption.

**Measured impact (pilot-scale, indicative):**

- **Decision cycle time:** 45 days (baseline: recurring “Are we ready?” debates) → 30 days (explicit risk posture reduces re-litigation)
- **Inspection findings tied to decision documentation:** reduced where RGDS coverage exists
- **Cost avoidance:** CAPA remediation reduced where log completeness and closure evidence exist
- **Stakeholder satisfaction:** improved clarity and confidence when logs are used consistently

---

### Research Challenges

**Challenge 1: Adoption resistance**  
Teams often perceive decision logs as “bureaucratic overhead” during compressed IND timelines. Common objection: “We’re already struggling to meet the submission deadline. Adding decision log authoring will slow us down.” [13](references/bibliography/#cite13)

**Mitigation:**

- Frame RGDS as decision acceleration rather than compliance. Pilot evidence suggests cycle-time compression (e.g., 45→30 days) when explicit risk posture prevents recurring re-litigation. [13](references/bibliography/#cite13)
- Keep authoring bounded: target **30–60 minutes per gate decision**, recovered through reduced rework and faster approvals.
- Start with decisions that face immediate scrutiny (inspection readiness, investor diligence) to make ROI visible quickly.
- Secure executive sponsorship so leadership models the behavior and removes ambiguity around “why we’re doing this.”

**Challenge 2: Retrospective capture**  
Teams ask whether logs can be created retrospectively for decisions made 6–12 months earlier. Retrospective logs fail the contemporaneity test: you cannot reliably prove what evidence was available at the time, and regulators may view it as post-hoc rationalization. [24](references/bibliography/#cite24) [25](references/bibliography/#cite25)

**Solution:** Apply RGDS prospectively. Preserve legacy artifacts for historical decisions, and enforce schema-validated logs for decisions after adoption.

**Challenge 3: Decision complexity**  
Some decisions span many stakeholders, large evidence sets, and weeks of deliberation (e.g., “Pursue Breakthrough Therapy Designation?”). The risk is that a log becomes a narrative document.

**Solution: Hierarchical decision logs**  
Use a parent decision that links to focused child decisions, each schema-validated:

- Parent: `RGDS-DEC-IND2026-2026-010` — “Pursue Breakthrough Therapy Designation?”
- Child A: “Does clinical data support substantial improvement?”
- Child B: “Does precedent support BTD for this indication?”
- Child C: “Does the commercial strategy justify the investment?”

The parent summarizes; the children carry evidence detail in bounded units.

---

### In sum: what this data says about Question 1

The reconstructability problem is primarily **governance, not data**. Sponsors often possess the studies and analyses reviewers need, but lack a disciplined method for recording how those inputs drove a decision at the moment it was made. RGDS does not replace scientific rigor or regulatory strategy. It standardizes decision documentation so inspectors, internal auditors, and investors can see why a team proceeded, what risks were accepted, and what conditions and contingencies were attached.

- Moving from ad-hoc minutes and email archaeology to schema-validated decision logs can shift reconstructability from weeks to minutes for decisions covered by logs.
- The mechanism is structural: required fields prevent silent assumptions; contemporaneous capture reduces post-hoc rationalization; version control supports auditability and retrieval.
- RGDS improves explainability and inspection readiness for decisions after adoption. It does not rehabilitate weak data packages or unlogged historical decisions.
- The pragmatic next step for most sponsors is a narrow pilot on a handful of near-term phase-gate decisions (data readiness, CMC readiness, key safety calls), then use the pilot to prove fast, consistent answers to “why did you proceed?” under scrutiny.
